{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import tensorly.backend as T\n",
    "\n",
    "class pruned_Dense(Layer):\n",
    "    def __init__(self, n_neurons_out, **kwargs):\n",
    "        self.n_neurons_out = n_neurons_out\n",
    "        super(pruned_Dense,self).__init__(**kwargs)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        #define the variables of this layer in the build function:\n",
    "        n_neurons_in = input_shape[1]\n",
    "        # print(n_neurons_in)\n",
    "        # print(self.n_neurons_out)\n",
    "        stdv = 1/np.sqrt(n_neurons_in)\n",
    "        w = np.random.normal(size=[n_neurons_in, self.n_neurons_out], loc=0.0, scale=stdv).astype(np.float32)\n",
    "        self.w = K.variable(w)\n",
    "        b = np.zeros(self.n_neurons_out)\n",
    "        self.b = K.variable(b)\n",
    "        # w is the weight matrix, b is the bias. These are the trainable variables of this layer.\n",
    "        self.trainable_weights = [self.w, self.b]\n",
    "        # mask is a non-trainable weight that simulates pruning. the values of mask should be either 1 or 0, where 0 will prune a weight. We initialize mask to all ones:\n",
    "        mask = np.ones((n_neurons_in, self.n_neurons_out))\n",
    "        self.mask = K.variable(mask)\n",
    "\n",
    "    def call(self, x):\n",
    "        # define the input-output relationship in this layer in this function\n",
    "        pruned_w = self.w * self.mask\n",
    "        out = K.dot(x, pruned_w)\n",
    "        out = out + self.b\n",
    "        return out\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        #define the shape of this layer's output:\n",
    "        return (input_shape[0], self.n_neurons_out)\n",
    "\n",
    "    def get_mask(self):\n",
    "        #get the mask values\n",
    "        return K.get_value(self.mask)\n",
    "\n",
    "    def set_mask(self, mask):\n",
    "        #set new mask values to this layer\n",
    "        K.set_value(self.mask, mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5,4,2)\n",
    "print(type(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "2\n",
      "1\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "modes=[2,3]\n",
    "for index, mode in enumerate(modes):\n",
    "    print(index)\n",
    "    print(mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partial_tucker(tensor, modes, rank=None, n_iter_max=100, init='svd', tol=10e-5,\n",
    "                   svd='numpy_svd', random_state=None, verbose=False, ranks=None):\n",
    "    \"\"\"Partial tucker decomposition via Higher Order Orthogonal Iteration (HOI)\n",
    "\n",
    "        Decomposes `tensor` into a Tucker decomposition exclusively along the provided modes.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : ndarray\n",
    "    modes : int list\n",
    "            list of the modes on which to perform the decomposition\n",
    "    ranks : None or int list\n",
    "            size of the core tensor, ``(len(ranks) == len(modes))``\n",
    "    rank : None or int\n",
    "            number of components\n",
    "    n_iter_max : int\n",
    "                 maximum number of iteration\n",
    "    init : {'svd', 'random'}, optional\n",
    "    svd : str, default is 'numpy_svd'\n",
    "        function to use to compute the SVD,\n",
    "        acceptable values in tensorly.SVD_FUNS\n",
    "    tol : float, optional\n",
    "          tolerance: the algorithm stops when the variation in\n",
    "          the reconstruction error is less than the tolerance\n",
    "    random_state : {None, int, np.random.RandomState}\n",
    "    verbose : int, optional\n",
    "        level of verbosity\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    core : ndarray\n",
    "            core tensor of the Tucker decomposition\n",
    "    factors : ndarray list\n",
    "            list of factors of the Tucker decomposition.\n",
    "            with ``core.shape[i] == (tensor.shape[i], ranks[i]) for i in modes``\n",
    "\n",
    "    \"\"\"\n",
    "    if ranks is not None:\n",
    "        message = \"'ranks' is depreciated, please use 'rank' instead\"\n",
    "        warnings.warn(message, DeprecationWarning)\n",
    "        rank = ranks\n",
    "\n",
    "    if rank is None:\n",
    "        message = \"No value given for 'rank'. The decomposition will preserve the original size.\"\n",
    "        warnings.warn(message, Warning)\n",
    "        rank = [tl.shape(tensor)[mode] for mode in modes]\n",
    "    elif isinstance(rank, int):\n",
    "        message = \"Given only one int for 'rank' instead of a list of {} modes. Using this rank for all modes.\".format(len(modes))\n",
    "        warnings.warn(message, Warning)\n",
    "        rank = [rank for _ in modes]\n",
    "\n",
    "    try:\n",
    "        svd_fun = tl.SVD_FUNS[svd]\n",
    "    except KeyError:\n",
    "        message = 'Got svd={}. However, for the current backend ({}), the possible choices are {}'.format(\n",
    "                svd, tl.get_backend(), tl.SVD_FUNS)\n",
    "        raise ValueError(message)\n",
    "\n",
    "    # SVD init\n",
    "    if init == 'svd':\n",
    "        factors = []\n",
    "        for index, mode in enumerate(modes):\n",
    "            eigenvecs, _, _ = svd_fun(unfold(tensor, mode), n_eigenvecs=rank[index], random_state=random_state)\n",
    "            factors.append(eigenvecs)\n",
    "    else:\n",
    "        rng = check_random_state(random_state)\n",
    "        core = tl.tensor(rng.random_sample(rank), **tl.context(tensor))\n",
    "        factors = [tl.tensor(rng.random_sample((tl.shape(tensor)[mode], rank[index])), **tl.context(tensor)) for (index, mode) in enumerate(modes)]\n",
    "\n",
    "    rec_errors = []\n",
    "    norm_tensor = tl.norm(tensor, 2)\n",
    "\n",
    "    for iteration in range(n_iter_max):\n",
    "        for index, mode in enumerate(modes):\n",
    "            core_approximation = multi_mode_dot(tensor, factors, modes=modes, skip=index, transpose=True)\n",
    "            eigenvecs, _, _ = svd_fun(unfold(core_approximation, mode), n_eigenvecs=rank[index], random_state=random_state)\n",
    "            factors[index] = eigenvecs\n",
    "\n",
    "        core = multi_mode_dot(tensor, factors, modes=modes, transpose=True)\n",
    "\n",
    "        # The factors are orthonormal and therefore do not affect the reconstructed tensor's norm\n",
    "        rec_error = sqrt(abs(norm_tensor**2 - tl.norm(core, 2)**2)) / norm_tensor\n",
    "        rec_errors.append(rec_error)\n",
    "\n",
    "        if iteration > 1:\n",
    "            if verbose:\n",
    "                print('reconstruction error={}, variation={}.'.format(\n",
    "                    rec_errors[-1], rec_errors[-2] - rec_errors[-1]))\n",
    "\n",
    "            if tol and abs(rec_errors[-2] - rec_errors[-1]) < tol:\n",
    "                if verbose:\n",
    "                    print('converged in {} iterations.'.format(iteration))\n",
    "                break\n",
    "\n",
    "    return core, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "from tensorly.base import unfold\n",
    "from tensorly.tenalg import multi_mode_dot, mode_dot\n",
    "from tensorly.tucker_tensor import tucker_to_tensor\n",
    "from tensorly.random import check_random_state\n",
    "from math import sqrt\n",
    "\n",
    "import warnings\n",
    "\n",
    "# Author: Jean Kossaifi <jean.kossaifi+tensors@gmail.com>\n",
    "\n",
    "# License: BSD 3 clause\n",
    "\n",
    "\n",
    "def partial_tucker(tensor, modes, rank=None, n_iter_max=100, init='svd', tol=10e-5,\n",
    "                   svd='numpy_svd', random_state=None, verbose=False, ranks=None):\n",
    "    \"\"\"Partial tucker decomposition via Higher Order Orthogonal Iteration (HOI)\n",
    "        Decomposes `tensor` into a Tucker decomposition exclusively along the provided modes.\n",
    "    Parameters\n",
    "    ----------\n",
    "    tensor : ndarray\n",
    "    modes : int list\n",
    "            list of the modes on which to perform the decomposition\n",
    "    ranks : None or int list\n",
    "            size of the core tensor, ``(len(ranks) == len(modes))``\n",
    "    rank : None or int\n",
    "            number of components\n",
    "    n_iter_max : int\n",
    "                 maximum number of iteration\n",
    "    init : {'svd', 'random'}, optional\n",
    "    svd : str, default is 'numpy_svd'\n",
    "        function to use to compute the SVD,\n",
    "        acceptable values in tensorly.SVD_FUNS\n",
    "    tol : float, optional\n",
    "          tolerance: the algorithm stops when the variation in\n",
    "          the reconstruction error is less than the tolerance\n",
    "    random_state : {None, int, np.random.RandomState}\n",
    "    verbose : int, optional\n",
    "        level of verbosity\n",
    "    Returns\n",
    "    -------\n",
    "    core : ndarray\n",
    "            core tensor of the Tucker decomposition\n",
    "    factors : ndarray list\n",
    "            list of factors of the Tucker decomposition.\n",
    "            with ``core.shape[i] == (tensor.shape[i], ranks[i]) for i in modes``\n",
    "    \"\"\"\n",
    "    if ranks is not None:\n",
    "        message = \"'ranks' is depreciated, please use 'rank' instead\"\n",
    "        warnings.warn(message, DeprecationWarning)\n",
    "        rank = ranks\n",
    "\n",
    "    if rank is None:\n",
    "        message = \"No value given for 'rank'. The decomposition will preserve the original size.\"\n",
    "        warnings.warn(message, Warning)\n",
    "        rank = [tl.shape(tensor)[mode] for mode in modes]\n",
    "    elif isinstance(rank, int):\n",
    "        message = \"Given only one int for 'rank' instead of a list of {} modes. Using this rank for all modes.\".format(len(modes))\n",
    "        warnings.warn(message, Warning)\n",
    "        rank = [rank for _ in modes]\n",
    "\n",
    "    try:\n",
    "        svd_fun = tl.SVD_FUNS[svd]\n",
    "    except KeyError:\n",
    "        message = 'Got svd={}. However, for the current backend ({}), the possible choices are {}'.format(\n",
    "                svd, tl.get_backend(), tl.SVD_FUNS)\n",
    "        raise ValueError(message)\n",
    "\n",
    "    # SVD init\n",
    "    if init == 'svd':\n",
    "        factors = []\n",
    "        for index, mode in enumerate(modes):\n",
    "            eigenvecs, _, _ = svd_fun(unfold(tensor, mode), n_eigenvecs=rank[index], random_state=random_state)\n",
    "            factors.append(eigenvecs)\n",
    "    else:\n",
    "        rng = check_random_state(random_state)\n",
    "        core = tl.tensor(rng.random_sample(rank), **tl.context(tensor))\n",
    "        factors = [tl.tensor(rng.random_sample((tl.shape(tensor)[mode], rank[index])), **tl.context(tensor)) for (index, mode) in enumerate(modes)]\n",
    "\n",
    "    rec_errors = []\n",
    "    norm_tensor = tl.norm(tensor, 2)\n",
    "\n",
    "    for iteration in range(n_iter_max):\n",
    "        for index, mode in enumerate(modes):\n",
    "            core_approximation = multi_mode_dot(tensor, factors, modes=modes, skip=index, transpose=True)\n",
    "            eigenvecs, _, _ = svd_fun(unfold(core_approximation, mode), n_eigenvecs=rank[index], random_state=random_state)\n",
    "            factors[index] = eigenvecs\n",
    "\n",
    "        core = multi_mode_dot(tensor, factors, modes=modes, transpose=True)\n",
    "\n",
    "        # The factors are orthonormal and therefore do not affect the reconstructed tensor's norm\n",
    "        rec_error = sqrt(abs(norm_tensor**2 - tl.norm(core, 2)**2)) / norm_tensor\n",
    "        rec_errors.append(rec_error)\n",
    "\n",
    "        if iteration > 1:\n",
    "            if verbose:\n",
    "                print('reconstruction error={}, variation={}.'.format(\n",
    "                    rec_errors[-1], rec_errors[-2] - rec_errors[-1]))\n",
    "\n",
    "            if tol and abs(rec_errors[-2] - rec_errors[-1]) < tol:\n",
    "                if verbose:\n",
    "                    print('converged in {} iterations.'.format(iteration))\n",
    "                break\n",
    "\n",
    "    return core, factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorly as tl\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import math\n",
    "from tensorly.decomposition import partial_tucker\n",
    "from tensorly import tucker_to_tensor\n",
    "import torch\n",
    "\n",
    "\n",
    "\n",
    "def decomposer(test, R1, R2):\n",
    "    print(test.shape)\n",
    "    core, factors = partial_tucker(test,ranks=[R1,R2], modes=[2,3])\n",
    "    modes=[2,3]\n",
    "    norm_tensor = tl.norm(test, 2)\n",
    "    for index, mode in enumerate(modes):\n",
    "        core_approximation = multi_mode_dot(test, factors, modes=modes, skip=index, transpose=True)\n",
    "        print(core_approximation.shape)\n",
    "    print(core.shape)\n",
    "    print(factors[0].shape)\n",
    "    print(factors[1].shape)\n",
    "    print('reconstructing')\n",
    "\n",
    "    # The factors are orthonormal and therefore do not affect the reconstructed tensor's norm\n",
    "    rec_error = sqrt(abs(norm_tensor**2 - tl.norm(core_approximation, 2)**2))\n",
    "    print(rec_error)\n",
    "    \n",
    "    \n",
    "    \n",
    "    mse = np.linalg.norm(test-core_approximation)\n",
    "    print(mse)\n",
    "    return rec_error;\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 1)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 1)\n",
      "(64, 64)\n",
      "(64, 1)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "140.29504789747284\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 2)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 2)\n",
      "(64, 64)\n",
      "(64, 2)\n",
      "reconstructing\n",
      "0.0\n",
      "192.80740990911892\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 3)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 3)\n",
      "(64, 64)\n",
      "(64, 3)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "225.352108249346\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 4)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 4)\n",
      "(64, 64)\n",
      "(64, 4)\n",
      "reconstructing\n",
      "0.0\n",
      "246.50131303709105\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 5)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 5)\n",
      "(64, 64)\n",
      "(64, 5)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "262.3907979859022\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 6)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 6)\n",
      "(64, 64)\n",
      "(64, 6)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "263.2285130890429\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 7)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 7)\n",
      "(64, 64)\n",
      "(64, 7)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "272.32820444863756\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 8)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 8)\n",
      "(64, 64)\n",
      "(64, 8)\n",
      "reconstructing\n",
      "0.0\n",
      "274.92806834463386\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 9)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 9)\n",
      "(64, 64)\n",
      "(64, 9)\n",
      "reconstructing\n",
      "0.0\n",
      "271.43798587988675\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 10)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 10)\n",
      "(64, 64)\n",
      "(64, 10)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "272.3578293888536\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 11)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 11)\n",
      "(64, 64)\n",
      "(64, 11)\n",
      "reconstructing\n",
      "0.0\n",
      "274.4447319426639\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 12)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 12)\n",
      "(64, 64)\n",
      "(64, 12)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "273.7458796508743\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 13)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 13)\n",
      "(64, 64)\n",
      "(64, 13)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "272.1245607096585\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 14)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 14)\n",
      "(64, 64)\n",
      "(64, 14)\n",
      "reconstructing\n",
      "0.0\n",
      "271.57025810089027\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 15)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 15)\n",
      "(64, 64)\n",
      "(64, 15)\n",
      "reconstructing\n",
      "0.0\n",
      "270.3214520443448\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 16)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 16)\n",
      "(64, 64)\n",
      "(64, 16)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "272.5271773140456\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 17)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 17)\n",
      "(64, 64)\n",
      "(64, 17)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "273.46847966466504\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 18)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 18)\n",
      "(64, 64)\n",
      "(64, 18)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "272.84427809981304\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 19)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 19)\n",
      "(64, 64)\n",
      "(64, 19)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "271.98993298654665\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 20)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 20)\n",
      "(64, 64)\n",
      "(64, 20)\n",
      "reconstructing\n",
      "0.0\n",
      "269.93439221447557\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 21)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 21)\n",
      "(64, 64)\n",
      "(64, 21)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "273.4091662859064\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 22)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 22)\n",
      "(64, 64)\n",
      "(64, 22)\n",
      "reconstructing\n",
      "0.0\n",
      "270.1820022145524\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 23)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 23)\n",
      "(64, 64)\n",
      "(64, 23)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "273.9187510617338\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 24)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 24)\n",
      "(64, 64)\n",
      "(64, 24)\n",
      "reconstructing\n",
      "0.0\n",
      "271.7311494335965\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 25)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 25)\n",
      "(64, 64)\n",
      "(64, 25)\n",
      "reconstructing\n",
      "0.0\n",
      "271.6766338332702\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 26)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 26)\n",
      "(64, 64)\n",
      "(64, 26)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "270.411621721747\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 27)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 27)\n",
      "(64, 64)\n",
      "(64, 27)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "275.2108322916513\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 28)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 28)\n",
      "(64, 64)\n",
      "(64, 28)\n",
      "reconstructing\n",
      "0.0\n",
      "270.3408695102959\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 29)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 29)\n",
      "(64, 64)\n",
      "(64, 29)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "274.9871227812087\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 30)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 30)\n",
      "(64, 64)\n",
      "(64, 30)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "270.1560860607162\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 31)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 31)\n",
      "(64, 64)\n",
      "(64, 31)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "273.55111081800635\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 32)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 32)\n",
      "(64, 64)\n",
      "(64, 32)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "271.17602954774185\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 33)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 33)\n",
      "(64, 64)\n",
      "(64, 33)\n",
      "reconstructing\n",
      "0.0\n",
      "272.04674102666877\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 34)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 34)\n",
      "(64, 64)\n",
      "(64, 34)\n",
      "reconstructing\n",
      "0.0\n",
      "275.19098676458225\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 35)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 35)\n",
      "(64, 64)\n",
      "(64, 35)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "270.01054068074154\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 36)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 36)\n",
      "(64, 64)\n",
      "(64, 36)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "272.19052988207943\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 37)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 37)\n",
      "(64, 64)\n",
      "(64, 37)\n",
      "reconstructing\n",
      "0.0\n",
      "274.9308993006464\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 38)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 38)\n",
      "(64, 64)\n",
      "(64, 38)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "275.84634740848287\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 39)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 39)\n",
      "(64, 64)\n",
      "(64, 39)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "274.10247825198695\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 40)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 40)\n",
      "(64, 64)\n",
      "(64, 40)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "268.39065139209595\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 41)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 41)\n",
      "(64, 64)\n",
      "(64, 41)\n",
      "reconstructing\n",
      "0.0\n",
      "275.4397895631118\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 42)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 42)\n",
      "(64, 64)\n",
      "(64, 42)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "269.9255099852489\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 43)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 43)\n",
      "(64, 64)\n",
      "(64, 43)\n",
      "reconstructing\n",
      "0.0\n",
      "274.10929439904004\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 44)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 44)\n",
      "(64, 64)\n",
      "(64, 44)\n",
      "reconstructing\n",
      "0.0\n",
      "274.9327504248568\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 45)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 45)\n",
      "(64, 64)\n",
      "(64, 45)\n",
      "reconstructing\n",
      "0.0\n",
      "273.06321609276614\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 46)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 46)\n",
      "(64, 64)\n",
      "(64, 46)\n",
      "reconstructing\n",
      "0.0\n",
      "270.9909091626413\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 47)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 47)\n",
      "(64, 64)\n",
      "(64, 47)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "273.7808888841823\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 48)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 48)\n",
      "(64, 64)\n",
      "(64, 48)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "271.088822340065\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 49)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 49)\n",
      "(64, 64)\n",
      "(64, 49)\n",
      "reconstructing\n",
      "0.0\n",
      "267.7764700932953\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 50)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 50)\n",
      "(64, 64)\n",
      "(64, 50)\n",
      "reconstructing\n",
      "0.0\n",
      "269.45703632731147\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 51)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 51)\n",
      "(64, 64)\n",
      "(64, 51)\n",
      "reconstructing\n",
      "0.0\n",
      "270.8889450284468\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 52)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 52)\n",
      "(64, 64)\n",
      "(64, 52)\n",
      "reconstructing\n",
      "0.0\n",
      "269.91782380815346\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 53)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 53)\n",
      "(64, 64)\n",
      "(64, 53)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "271.25869790207537\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 54)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 54)\n",
      "(64, 64)\n",
      "(64, 54)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "269.6699859809054\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 55)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 55)\n",
      "(64, 64)\n",
      "(64, 55)\n",
      "reconstructing\n",
      "0.0\n",
      "271.40510588814436\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 56)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 56)\n",
      "(64, 64)\n",
      "(64, 56)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "270.50300760219903\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 57)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 57)\n",
      "(64, 64)\n",
      "(64, 57)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "271.89142449056885\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 58)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 58)\n",
      "(64, 64)\n",
      "(64, 58)\n",
      "reconstructing\n",
      "0.0\n",
      "268.8140701582447\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 59)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 59)\n",
      "(64, 64)\n",
      "(64, 59)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "269.08002639516525\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 60)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 60)\n",
      "(64, 64)\n",
      "(64, 60)\n",
      "reconstructing\n",
      "0.0\n",
      "272.43897192060723\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 61)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 61)\n",
      "(64, 64)\n",
      "(64, 61)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "269.4438129064339\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 62)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 62)\n",
      "(64, 64)\n",
      "(64, 62)\n",
      "reconstructing\n",
      "2.6973983046972182e-06\n",
      "272.23424197446576\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 63)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 63)\n",
      "(64, 64)\n",
      "(64, 63)\n",
      "reconstructing\n",
      "3.814697265625e-06\n",
      "268.77228246725076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x17072a2c4e0>]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tensorly.backend as T\n",
    "\n",
    "test = np.random.randn(3,3,64,64)\n",
    "answer = []\n",
    "for i in range(1,64):\n",
    "    answer.append(decomposer(test,64,i))\n",
    "\n",
    "plt.plot(answer)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 1, 64)\n",
      "(3, 3, 1, 64)\n",
      "(64, 1)\n",
      "(64, 64)\n",
      "reconstructing\n",
      "0.9863003251278936\n",
      "314.3077029287048\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 64, 64)\n",
      "(3, 3, 2, 64)\n",
      "(3, 3, 2, 64)\n",
      "(64, 2)\n",
      "(64, 64)\n",
      "reconstructing\n",
      "0.9726483785013235\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (3,3,64,64) (3,3,2,64) ",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-d9d3810fce96>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m     \u001b[0manswer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdecomposer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0manswer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-71-99e816379345>\u001b[0m in \u001b[0;36mdecomposer\u001b[1;34m(test, R1, R2)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 30\u001b[1;33m     \u001b[0mmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mcore_approximation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     31\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmse\u001b[0m\u001b[1;33m;\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: operands could not be broadcast together with shapes (3,3,64,64) (3,3,2,64) "
     ]
    }
   ],
   "source": [
    "answer = []\n",
    "for i in range(1,64):\n",
    "    answer.append(decomposer(test,i,64))\n",
    "\n",
    "plt.plot(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import cifar10\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "X_train=X_train.astype(np.float32)\n",
    "X_test=X_test.astype(np.float32)\n",
    "Y_train = np_utils.to_categorical(y_train, 10)\n",
    "Y_test = np_utils.to_categorical(y_test, 10)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "X_train=2*X_train-1\n",
    "X_test=2*X_test-1\n",
    "\n",
    "data_train = X_train\n",
    "labels_train = Y_train\n",
    "data_test = X_test\n",
    "labels_test = Y_test\n",
    "print('X_train shape:', X_train.shape)\n",
    "print(X_train.shape[0], 'train samples')\n",
    "print(X_test.shape[0], 'test samples')\n",
    "\n",
    "batch_size=100\n",
    "lr=0.001\n",
    "Training=True\n",
    "Compressing=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv2d_7/BiasAdd:0\", shape=(?, 30, 30, 64), dtype=float32)\n",
      "Tensor(\"activation_10/Relu:0\", shape=(?, 30, 30, 64), dtype=float32)\n",
      "Tensor(\"batch_normalization_9/cond/Merge:0\", shape=(?, 30, 30, 64), dtype=float32)\n",
      "Tensor(\"conv2d_8/BiasAdd:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"activation_11/Relu:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"batch_normalization_10/cond/Merge:0\", shape=(?, 28, 28, 64), dtype=float32)\n",
      "Tensor(\"max_pooling2d_3/MaxPool:0\", shape=(?, 14, 14, 64), dtype=float32)\n",
      "Tensor(\"conv2d_9/BiasAdd:0\", shape=(?, 12, 12, 128), dtype=float32)\n",
      "Tensor(\"activation_12/Relu:0\", shape=(?, 12, 12, 128), dtype=float32)\n",
      "Tensor(\"batch_normalization_11/cond/Merge:0\", shape=(?, 12, 12, 128), dtype=float32)\n",
      "Tensor(\"conv2d_10/BiasAdd:0\", shape=(?, 10, 10, 128), dtype=float32)\n",
      "Tensor(\"activation_13/Relu:0\", shape=(?, 10, 10, 128), dtype=float32)\n",
      "Tensor(\"batch_normalization_12/cond/Merge:0\", shape=(?, 10, 10, 128), dtype=float32)\n",
      "Tensor(\"max_pooling2d_4/MaxPool:0\", shape=(?, 5, 5, 128), dtype=float32)\n",
      "Tensor(\"conv2d_11/BiasAdd:0\", shape=(?, 3, 3, 256), dtype=float32)\n",
      "Tensor(\"activation_14/Relu:0\", shape=(?, 3, 3, 256), dtype=float32)\n",
      "Tensor(\"batch_normalization_13/cond/Merge:0\", shape=(?, 3, 3, 256), dtype=float32)\n",
      "Tensor(\"conv2d_12/BiasAdd:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"activation_15/Relu:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"batch_normalization_14/cond/Merge:0\", shape=(?, 1, 1, 256), dtype=float32)\n",
      "Tensor(\"flatten_2/Reshape:0\", shape=(?, ?), dtype=float32)\n",
      "Tensor(\"dense_4/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"activation_16/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"batch_normalization_15/cond/Merge:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"dense_5/BiasAdd:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"activation_17/Relu:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"batch_normalization_16/cond/Merge:0\", shape=(?, 512), dtype=float32)\n",
      "Tensor(\"dense_6/BiasAdd:0\", shape=(?, 10), dtype=float32)\n",
      "Tensor(\"activation_18/Softmax:0\", shape=(?, 10), dtype=float32)\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 89.94%\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Activation, Input, Lambda, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "from keras import backend as K\n",
    "from keras.engine.topology import Layer\n",
    "import numpy as np\n",
    "\n",
    "from keras.datasets import cifar10\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import backend as K\n",
    "import pickle\n",
    "\n",
    "\n",
    "def get_model():\n",
    "\tbatch_norm_alpha=0.9\n",
    "\tbatch_norm_eps=1e-4\n",
    "\n",
    "\tmodel=Sequential()\n",
    "\n",
    "\tmodel.add(Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid',input_shape=[32,32,3]))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Conv2D(filters=64, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "\tmodel.add(Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Conv2D(filters=128, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "\tmodel.add(Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Conv2D(filters=256, kernel_size=3, strides=(1, 1), padding='valid'))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\t#model.add(MaxPooling2D(pool_size=(2, 2),strides=(2,2)))\n",
    "\n",
    "\tmodel.add(Flatten())\n",
    "\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Dense(512))\n",
    "\tmodel.add(Activation('relu'))\n",
    "\tmodel.add(BatchNormalization(axis=-1, momentum=batch_norm_alpha, epsilon=batch_norm_eps))\n",
    "\tmodel.add(Dense(10))\n",
    "\tmodel.add(Activation('softmax'))\n",
    "\n",
    "\treturn model\n",
    "\n",
    "\n",
    "model=get_model()\n",
    "for i in range(len(model.layers)):\n",
    " \n",
    "    print(model.get_layer(index=i).output)\n",
    "\n",
    "weights_path='pretrained_cifar10.h5'\n",
    "model.load_weights(weights_path)\n",
    "opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "#loss1 = tf.keras.losses.sparse_categorical_crossentropy()\n",
    "\n",
    "\n",
    "model.compile(optimizer=opt, \n",
    "              loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "#history_dropout_hidden = model.fit(data_train, labels_train, validation_data=(data_test, labels_test), epochs=50, batch_size=1000, shuffle=True)\n",
    "scores_dropout_hidden = model.evaluate(data_test, labels_test)\n",
    "print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))\n",
    "#complie the model with sparse categorical crossentropy loss function as you did in part 1\n",
    "\n",
    "#make sure weights are loaded correctly by evaluating the model here and printing the output\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "(3, 3, 3, 64)\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "(3, 3, 64, 64)\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "(3, 3, 64, 128)\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "(3, 3, 128, 128)\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "(3, 3, 128, 256)\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "(3, 3, 256, 256)\n"
     ]
    }
   ],
   "source": [
    "for i in model.layers:\n",
    "    if type(i) == keras.layers.convolutional.Conv2D:\n",
    "        print(type(i))\n",
    "        print(i.get_weights()[0].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            weight = i.get_weights()\n",
    "            print(weight[0].shape)\n",
    "            biastemp = np.zeros(3)#np.zeros(weight[1].shape)\n",
    "            loss, core, I, O = decompose(weight[0],[64,64])\n",
    "            I = np.expand_dims(I, axis=0)\n",
    "            I = np.expand_dims(I, axis=0)\n",
    "            print(loss)\n",
    "            \n",
    "            first = 0;\n",
    "            filtershape = int(i.kernel[0].shape[0])           #being used in 2nd layer , k \n",
    "            print(filtershape)\n",
    "            print(i.filters)           \n",
    "    \n",
    "            print(layer1.set_weights([I,biastemp]))\n",
    "            print(layer2.set_weights([core,biastemp]))\n",
    "            print(layer3.set_weights(O))\n",
    "            \n",
    "                        \n",
    "            print(dir(i))\n",
    "            weight = i.get_weights()\n",
    "            print(type(weight[0]))\n",
    "            print(weight[0].shape)\n",
    "            loss, core, I, O = decompose(weight[0],[64,64])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorly.decomposition import partial_tucker\n",
    "from tensorly.tenalg import multi_mode_dot, mode_dot\n",
    "\n",
    "def decompose(value,rank):\n",
    "    print(value.shape)\n",
    "    #value = tf.convert_to_tensor(value)\n",
    "    core,[I,O] = partial_tucker(value,modes = [2,3],ranks = rank)\n",
    "    #core = tf.convert_to_tensor(core)\n",
    "    #I = tf.convert_to_tensor(I)\n",
    "    #O = tf.convert_to_tensor(O)\n",
    "    #reconstruct = tf.matmul(tf.matmul(I,core),O.T)\n",
    "    reconstruct = np.zeros((value.shape[0],value.shape[1],value.shape[2],value.shape[3]))\n",
    "    modes=[2,3]\n",
    "    factors = [I,O]\n",
    "    for i in range(0,core.shape[0]):\n",
    "        for j in range(0,core.shape[1]):\n",
    "            for k in range(0,core.shape[3]):\n",
    "                reconstruct[i,j,:,k] = np.dot(I,core[i,j,:,k])\n",
    "\n",
    "    for i in range(0,core.shape[0]):\n",
    "        for j in range(0,core.shape[1]):\n",
    "            for k in range(0,core.shape[2]):\n",
    "                reconstruct[i,j,k,:] = np.dot(core[i,j,k,:],O.T)\n",
    "    #for index, mode in enumerate(modes):\n",
    "        #print(index)\n",
    "        #print(modes)\n",
    "        #if index - 1 == 0:\n",
    "        #    core_approximation = multi_mode_dot(core, factors, modes=modes, skip=index, transpose=True)\n",
    "        #    print(core_approximation.shape)\n",
    "        #else:\n",
    "        #    core_approximation = multi_mode_dot(core, factors, modes=modes, skip=index, transpose=False)\n",
    "        #    print(core_approximation.shape)\n",
    "    \n",
    "    return np.linalg.norm(value-reconstruct), core, I, O "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            print('filter number:')\n",
    "            print(i.filters)\n",
    "            weight = i.get_weights()\n",
    "            k,k,c,f = weight[0].shape;\n",
    "            loss, core, I, O = decompose(weight[0],[22,21])\n",
    "            O = O.T\n",
    "\n",
    "            relativeweights.append(I);\n",
    "            relativeweights.append(core)\n",
    "            relativeweights.append(O)\n",
    "            \n",
    "            layer1 = Conv2D(filters=I.shape[1], kernel_size=1, strides=(1, 1), padding='valid',input_shape=[32,32,3])\n",
    "            layer2 = Conv2D(filters=O.shape[0], kernel_size=i.kernel_size, strides=(1, 1), padding='valid')\n",
    "            layer3 = Conv2D(filters=i.filters, kernel_size=1, strides=(1, 1), padding='valid')\n",
    "            model2.add(layer1)\n",
    "            model2.add(layer2)\n",
    "            model2.add(layer3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "filter number:\n",
      "64\n",
      "(3, 3, 3, 64)\n",
      "filter number:\n",
      "64\n",
      "(3, 3, 64, 64)\n",
      "filter number:\n",
      "128\n",
      "(3, 3, 64, 128)\n",
      "filter number:\n",
      "128\n",
      "(3, 3, 128, 128)\n",
      "filter number:\n",
      "256\n",
      "(3, 3, 128, 256)\n",
      "filter number:\n",
      "256\n",
      "(3, 3, 256, 256)\n",
      "18\n"
     ]
    }
   ],
   "source": [
    "def convert_to_masked_model(model):\n",
    "    batch_norm_alpha=0.9\n",
    "    batch_norm_eps=1e-4\n",
    "    \n",
    "    R1 = 22\n",
    "    R2 = 21\n",
    "    relativeweights = []\n",
    "    model2=Sequential()\n",
    "    first = 1;\n",
    "    for i in model.layers:\n",
    "        #if type(i) == keras.layers.convolutional.Conv2D:\n",
    "        #if type(i) == keras.layers.core.Dense:\n",
    "        if type(i) != keras.layers.convolutional.Conv2D:\n",
    "            model2.add(i)\n",
    "        elif type(i) == keras.layers.convolutional.Conv2D and first == 1:\n",
    "            model2.add(i)\n",
    "            first = 0;\n",
    "        else:\n",
    "            weight = i.get_weights()\n",
    "            print('filter number:')\n",
    "            print(i.filters)\n",
    "            k,k,c,f = weight[0].shape;\n",
    "            loss, core, I, O = decompose(weight[0],[22,21])\n",
    "            O = O.T\n",
    "            relativeweights.append(I);\n",
    "            relativeweights.append(core)\n",
    "            relativeweights.append(O)\n",
    "            \n",
    "            layer1 = Conv2D(filters=I.shape[1], kernel_size=1, strides=(1, 1), padding='valid')\n",
    "            layer2 = Conv2D(filters=O.shape[0], kernel_size=i.kernel_size, strides=(1, 1), padding='valid')\n",
    "            layer3 = Conv2D(filters=i.filters, kernel_size=1, strides=(1, 1), padding='valid')\n",
    "            model2.add(layer1)\n",
    "            model2.add(layer2)\n",
    "            model2.add(layer3)\n",
    "            \n",
    "    \n",
    "    return model2, relativeweights\n",
    "test,relativeweights = convert_to_masked_model(model)\n",
    "print(len(relativeweights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weightsetter(model, relativeweights):\n",
    "    index = 0\n",
    "    for i in model.layers:\n",
    "        if type(i) == keras.layers.convolutional.Conv2D:\n",
    "            if len(relativeweights[index].shape)>3:\n",
    "                kernel = relativeweights[index]\n",
    "\n",
    "                bias = np.zeros(kernel.shape[3])\n",
    "                i.set_weights([kernel,bias])\n",
    "                index = index+1;\n",
    "            else:\n",
    "                kernel = relativeweights[index]\n",
    "\n",
    "                kernel = relativeweights[index]\n",
    "                bias = np.zeros(kernel.shape[1])\n",
    "\n",
    "                kernel = np.expand_dims(kernel, axis=0)\n",
    "                kernel = np.expand_dims(kernel, axis=0)\n",
    "\n",
    "                i.set_weights([kernel,bias])\n",
    "                index = index+1;\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 1, 3, 3)\n",
      "(3, 3, 3, 21)\n",
      "(1, 1, 21, 64)\n",
      "(1, 1, 64, 22)\n",
      "(3, 3, 22, 21)\n",
      "(1, 1, 21, 64)\n",
      "(1, 1, 64, 22)\n",
      "(3, 3, 22, 21)\n",
      "(1, 1, 21, 128)\n",
      "(1, 1, 128, 22)\n",
      "(3, 3, 22, 21)\n",
      "(1, 1, 21, 128)\n",
      "(1, 1, 128, 22)\n",
      "(3, 3, 22, 21)\n",
      "(1, 1, 21, 256)\n",
      "(1, 1, 256, 22)\n",
      "(3, 3, 22, 21)\n",
      "(1, 1, 21, 256)\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(3, 3)\n",
      "layer shape:\n",
      "(1, 1, 3, 3)\n",
      "---------------------------\n",
      "setting middle layer\n",
      "core shape:\n",
      "(3, 3, 3, 21)\n",
      "layer shape:\n",
      "(3, 3, 3, 21)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(21, 64)\n",
      "layer shape:\n",
      "(1, 1, 21, 64)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(64, 22)\n",
      "layer shape:\n",
      "(1, 1, 64, 22)\n",
      "---------------------------\n",
      "setting middle layer\n",
      "core shape:\n",
      "(3, 3, 22, 21)\n",
      "layer shape:\n",
      "(3, 3, 22, 21)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(21, 64)\n",
      "layer shape:\n",
      "(1, 1, 21, 64)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(64, 22)\n",
      "layer shape:\n",
      "(1, 1, 64, 22)\n",
      "---------------------------\n",
      "setting middle layer\n",
      "core shape:\n",
      "(3, 3, 22, 21)\n",
      "layer shape:\n",
      "(3, 3, 22, 21)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(21, 128)\n",
      "layer shape:\n",
      "(1, 1, 21, 128)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(128, 22)\n",
      "layer shape:\n",
      "(1, 1, 128, 22)\n",
      "---------------------------\n",
      "setting middle layer\n",
      "core shape:\n",
      "(3, 3, 22, 21)\n",
      "layer shape:\n",
      "(3, 3, 22, 21)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(21, 128)\n",
      "layer shape:\n",
      "(1, 1, 21, 128)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(128, 22)\n",
      "layer shape:\n",
      "(1, 1, 128, 22)\n",
      "---------------------------\n",
      "setting middle layer\n",
      "core shape:\n",
      "(3, 3, 22, 21)\n",
      "layer shape:\n",
      "(3, 3, 22, 21)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(21, 256)\n",
      "layer shape:\n",
      "(1, 1, 21, 256)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(256, 22)\n",
      "layer shape:\n",
      "(1, 1, 256, 22)\n",
      "---------------------------\n",
      "setting middle layer\n",
      "core shape:\n",
      "(3, 3, 22, 21)\n",
      "layer shape:\n",
      "(3, 3, 22, 21)\n",
      "---------------------------\n",
      "setting bothside weight:\n",
      "setting middle layer\n",
      "core shape:\n",
      "(21, 256)\n",
      "layer shape:\n",
      "(1, 1, 21, 256)\n",
      "---------------------------\n",
      "10000/10000 [==============================] - 36s 4ms/step\n",
      "Accuracy: 24.79%\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.Adam(lr=0.001,decay=1e-6)\n",
    "test.compile(optimizer=opt, \n",
    "                  loss=\"categorical_crossentropy\" ,metrics=['accuracy'])\n",
    "for i in test.layers:\n",
    "    if type(i) == keras.layers.convolutional.Conv2D:\n",
    "        print(i.get_weights()[0].shape)\n",
    "test = weightsetter(test,relativeweights)\n",
    "scores_dropout_hidden = test.evaluate(data_test, labels_test)\n",
    "print(\"Accuracy: %.2f%%\" %(scores_dropout_hidden[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.pooling.MaxPooling2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.convolutional.Conv2D'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.core.Flatten'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n",
      "<class 'keras.layers.normalization.BatchNormalization'>\n",
      "<class 'keras.layers.core.Dense'>\n",
      "<class 'keras.layers.core.Activation'>\n"
     ]
    }
   ],
   "source": [
    "for i in test.layers:\n",
    "    print(type(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3, 3)\n",
      "(3, 3, 3, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(3, 3, 64, 64)\n",
      "(64, 64)\n",
      "(64, 64)\n",
      "(3, 3, 64, 64)\n",
      "(64, 128)\n",
      "(128, 64)\n",
      "(3, 3, 64, 64)\n",
      "(64, 128)\n",
      "(128, 64)\n",
      "(3, 3, 64, 64)\n",
      "(64, 256)\n",
      "(256, 64)\n",
      "(3, 3, 64, 64)\n",
      "(64, 256)\n"
     ]
    }
   ],
   "source": [
    "for i in relativeweights:\n",
    "    print(i.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
